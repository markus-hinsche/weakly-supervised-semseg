{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"../\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import (IMAGE_DATA_DIR, GT_DIR, IMAGE_DATA_TILES_DIR, GT_TILES_DIR, \n",
    "                    GT_ADJ_TILES_DIR, TILES_DIR, LABELS, RED, BLACK, N1, N2, N_validation,\n",
    "                    CODES\n",
    "                   )\n",
    "from loss_custom import WeakCrossEntropy\n",
    "from metrics_custom import acc_satellite, acc_weakly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://docs.fast.ai/dev/test.html#getting-reproducible-results\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# python RNG\n",
    "import random\n",
    "random.seed(seed)\n",
    "\n",
    "# pytorch RNGs\n",
    "import torch\n",
    "torch.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "# numpy RNG\n",
    "import numpy as np\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path('').absolute().parent; BASE_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fully-supervised (FS) Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_tiles_dir = GT_ADJ_TILES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tiles_fnames = os.listdir(BASE_DIR / IMAGE_DATA_TILES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = image_tiles_fnames[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_image( BASE_DIR / IMAGE_DATA_TILES_DIR / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_image(BASE_DIR / gt_tiles_dir / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = open_mask(BASE_DIR / gt_tiles_dir / fname)\n",
    "# mask.show(figsize=(5,5), alpha=1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_size = np.array(mask.shape[1:])\n",
    "src_size,mask.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_fn(x):\n",
    "    return BASE_DIR / gt_tiles_dir / x.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free = gpu_mem_get_free_no_cache(); free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"top_mosaic_09cm_area\"\n",
    "prog = re.compile(fr\"{base_path}(?P<area_id>\\d+)_tile(?P<tile_id>\\d+).tif\")\n",
    "\n",
    "def is_in_set(x, N):\n",
    "    fname = x.name  # e.g.: top_mosaic_09cm_area30_tile120.tif'\n",
    "\n",
    "    match_result = prog.search(fname)\n",
    "    area_id = match_result.group('area_id')\n",
    "    tile_id = match_result.group('tile_id')\n",
    "    image_fname = f\"{base_path}{area_id}.tif\"  # e.g.: top_mosaic_09cm_area30.tif'\n",
    "    return image_fname in N\n",
    "\n",
    "is_in_set_n1 = partial(is_in_set, N=N1)\n",
    "is_in_set_n2 = partial(is_in_set, N=N2)\n",
    "is_in_set_nvalidation = partial(is_in_set, N=N_validation)\n",
    "is_in_set_n1_or_nvalidation = partial(is_in_set, N=N1+N_validation)\n",
    "\n",
    "codes = LABELS+[RED, BLACK]\n",
    "\n",
    "src_size = np.array(mask.shape[1:])\n",
    "src_size,mask.data\n",
    "size = src_size // 2  # TODO\n",
    "\n",
    "fs_item_list = (SegmentationItemList.from_folder(BASE_DIR / IMAGE_DATA_TILES_DIR)  #returns SegmentationItemList\n",
    "             .filter_by_func(is_in_set_n1_or_nvalidation)  #returns SegmentationItemList\n",
    "             .split_by_valid_func(is_in_set_nvalidation)  #returns ItemLists(SegmentationItemList, SegmentationItemList)\n",
    "             .label_from_func(get_y_fn, classes=codes)  #returns LabelLists(LabelList, SegmentationItemList)\n",
    "             .transform(get_transforms(), size=size, tfm_y=True)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "fs_data = fs_item_list.databunch(bs=bs).normalize(imagenet_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Train and compare semantic segmentation networks, using the following data: Task (i) N1 pixel level labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_find(learn)\n",
    "# learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_learn = unet_learner(fs_data, models.resnet18, metrics=acc_satellite, wd=wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_learn.fit_one_cycle(20, slice(lr), pct_start=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_learn.save('mixed-stage-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_learn.load('mixed-stage-1');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs_learn.recorder.plot_losses()\n",
    "fs_learn.recorder.plot_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weakly-supervised (WS) Semantic Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tiles_fnames = os.listdir(BASE_DIR / TILES_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = image_tiles_fnames[0]; fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = open_image(BASE_DIR / TILES_DIR / fname)\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_size = np.array(img.shape[1:]); src_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"top_mosaic_09cm_area\"\n",
    "prog_label_vector = re.compile(base_path + r\"\\d+_tile\\d+_(?P<label_vector>\\d{5}).tif\")\n",
    "\n",
    "def get_y_fn(x):\n",
    "    fname = x.name\n",
    "    match_result = prog_label_vector.search(fname)\n",
    "    label_vector = match_result.group('label_vector')\n",
    "    label_vector_arr = torch.tensor(list(map(int,label_vector))) # NEW\n",
    "\n",
    "    indexes = torch.where(label_vector_arr == 1)[0]\n",
    "    colors = [LABELS[idx] for idx in indexes]\n",
    "    \n",
    "    assert 0<len(indexes)<6, (len(indexes), x)\n",
    "    \n",
    "    return colors\n",
    "\n",
    "def has_a_valid_color(x):\n",
    "    fname = x.name\n",
    "    match_result = prog_label_vector.search(fname)\n",
    "    label_vector = match_result.group('label_vector')\n",
    "    label_vector_arr = torch.tensor(list(map(int,label_vector))) # NEW\n",
    "\n",
    "    indexes = torch.where(label_vector_arr == 1)[0]\n",
    "    if not (0<len(indexes)<6):\n",
    "        print(\"not valid color\", len(indexes), x)\n",
    "        return False\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # DEBUG\n",
    "# # # Example: top_mosaic_09cm_area27_tile154_11100.tif\n",
    "# fpath = BASE_DIR / TILES_DIR / fname\n",
    "# result = get_y_fn(fpath)\n",
    "# type(result), result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "free = gpu_mem_get_free_no_cache(); free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"top_mosaic_09cm_area\"\n",
    "prog_with_label_vector = re.compile(base_path + r\"(?P<area_id>\\d+)_tile(?P<tile_id>\\d+)_(?P<label_vector>\\d{5}).tif\")\n",
    "\n",
    "def is_in_set(x, N):\n",
    "    fname = x.name  # e.g.: top_mosaic_09cm_area30_tile120.tif'\n",
    "\n",
    "    match_result = prog_with_label_vector.search(fname)\n",
    "    area_id = match_result.group('area_id')\n",
    "    tile_id = match_result.group('tile_id')\n",
    "    image_fname = f\"{base_path}{area_id}.tif\"  # e.g.: top_mosaic_09cm_area30.tif'\n",
    "    return image_fname in N\n",
    "\n",
    "is_in_set_n1 = partial(is_in_set, N=N1)\n",
    "is_in_set_n2 = partial(is_in_set, N=N2)\n",
    "is_in_set_nvalidation = partial(is_in_set, N=N_validation)\n",
    "is_in_set_n1_or_nvalidation = partial(is_in_set, N=N1+N_validation)\n",
    "is_in_set_n2_or_nvalidation = partial(is_in_set, N=N2+N_validation)\n",
    "\n",
    "src_size = np.array(img.shape[1:])\n",
    "src_size,img.data\n",
    "size = src_size // 2  # TODO\n",
    "\n",
    "# codes = CODES\n",
    "# codes = LABELS+[RED, BLACK]\n",
    "\n",
    "ws_item_list = (ImageList.from_folder(BASE_DIR / TILES_DIR)  #returns ImageList\n",
    "             .filter_by_func(is_in_set_n2_or_nvalidation)  #returns ImageList\n",
    "             .filter_by_func(has_a_valid_color)            #returns ImageList\n",
    "             .split_by_valid_func(is_in_set_nvalidation)  #returns ItemLists(ImageList, ImageList)\n",
    "             .label_from_func(get_y_fn, classes=LABELS)  #returns LabelLists(ImageList, MultiCategoryList)\n",
    "             .transform(get_transforms(), size=size)\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 64\n",
    "ws_data = ws_item_list.databunch(bs=bs).normalize(imagenet_stats)\n",
    "ws_data.c = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "Train and compare semantic segmentation networks, using the following data: Task (i) N1 pixel level labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wd=0.1 # TODO\n",
    "wd=0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_learn = unet_learner(ws_data, \n",
    "                     models.resnet18, \n",
    "                     loss_func=WeakCrossEntropy(CODES, axis=1),\n",
    "                     metrics=acc_weakly, \n",
    "                     wd=wd,\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_find(ws_learn)\n",
    "ws_learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_learn.fit_one_cycle(20, slice(lr), pct_start=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_learn.recorder.plot_losses(skip_start=50, show_grid=True)\n",
    "ws_learn.recorder.plot_metrics(skip_start=50, show_grid=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_learn.save('mixed-stage-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_learn.load('mixed-stage-2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-4.m50",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-4:m50"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
